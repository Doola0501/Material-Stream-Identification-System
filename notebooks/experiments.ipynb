{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04d9b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import os\n",
    "from collections import Counter\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import albumentations as A\n",
    "from joblib import Parallel, delayed\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efd6293",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare variables and create augmented directories\n",
    "dataset_path = \"../dataset\"\n",
    "classes = [\"glass\", \"paper\", \"cardboard\", \"plastic\", \"metal\", \"trash\"]\n",
    "img_size = (64, 64)  \n",
    "target_size=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e710fcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into train and test sets\n",
    "all_files = []\n",
    "all_labels = []\n",
    "\n",
    "for idx, cls in enumerate(classes):\n",
    "    class_folder = os.path.join(dataset_path, cls)\n",
    "    if not os.path.isdir(class_folder):\n",
    "        print(f\"Warning: Folder not found: {class_folder}\")\n",
    "        continue\n",
    "\n",
    "    for f in os.listdir(class_folder):\n",
    "        if not (f.endswith(\".jpg\") or f.endswith(\".png\")):\n",
    "            continue\n",
    "        file_path = os.path.join(class_folder, f)\n",
    "\n",
    "        img = cv2.imread(file_path)\n",
    "        if img is None:\n",
    "            print(f\"Warning: Cannot open image {file_path}, skipping.\")\n",
    "            continue\n",
    "\n",
    "        all_files.append(file_path)\n",
    "        all_labels.append(idx)\n",
    "\n",
    "train_files, test_files, train_labels, test_labels = train_test_split(\n",
    "    all_files, all_labels, test_size=0.35, random_state=42, stratify=all_labels\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(train_files)} images\")\n",
    "print(f\"Test: {len(test_files)} images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde96afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define augmentation pipeline\n",
    "random.seed(None)\n",
    "np.random.seed(None)\n",
    "\n",
    "transform = A.Compose([\n",
    "    A.SomeOf([\n",
    "        A.HorizontalFlip(p=0.7),\n",
    "        A.VerticalFlip(p=.7),\n",
    "        A.Rotate(limit=50, p=.8),\n",
    "        A.RandomScale(scale_limit=0.2, p=.5),\n",
    "        A.RandomBrightnessContrast(p=0.5),\n",
    "        A.GaussianBlur(p=0.3),\n",
    "        A.GaussNoise(p=0.1),\n",
    "        A.ColorJitter(p=1),\n",
    "    A.CenterCrop(width=128, height=128, p=.1),\n",
    "        A.Resize(width=random.randint(64, 256), height=random.randint(64, 256), p=1.0)\n",
    "    ], n=4)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9062d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform data augmentation\n",
    "def data_autgmentation(img_path, output_folder, aug_times=5):\n",
    "    img_name = os.path.basename(img_path)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(f\"❌ ERROR: Cannot load image {img_path}. Skipping.\")\n",
    "        return\n",
    "    for i in range(aug_times):\n",
    "        augmented = transform(image=img)\n",
    "        aug_img = augmented[\"image\"]\n",
    "        aug_img_name = f\"{os.path.splitext(img_name)[0]}_aug_{i+1}.jpg\"\n",
    "        aug_img_path = os.path.join(output_folder, aug_img_name)\n",
    "        cv2.imwrite(aug_img_path, aug_img)\n",
    "    print(f\"✅ Augmented {aug_times} images for {img_name}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e973d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment training images by 500 images per class\n",
    "class_counts = Counter(train_labels)\n",
    "\n",
    "for cls_idx, cls_name in enumerate(classes):\n",
    "    \n",
    "    cls_images = [img for i, img in enumerate(train_files) if train_labels[i] == cls_idx]\n",
    "    current_count = class_counts[cls_idx]\n",
    "    aug_needed = max(0, target_size - current_count)\n",
    "    \n",
    "    if aug_needed == 0:\n",
    "        continue\n",
    "    \n",
    "    output_folder = os.path.join(dataset_path, cls_name, \"augmented\")\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Distribute augmentations across available images\n",
    "    times_per_image = math.ceil(aug_needed / len(cls_images))\n",
    "    \n",
    "    for img_path in tqdm(cls_images, desc=f\"Augmenting {cls_name}\"):\n",
    "        data_autgmentation(img_path, output_folder, times_per_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e038d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all augmented images, copy them to train_files and train_labels\n",
    "for cls in classes:\n",
    "    aug_folder = os.path.join(dataset_path, cls, \"augmented\")\n",
    "    if not os.path.isdir(aug_folder):\n",
    "        continue\n",
    "    for f in os.listdir(aug_folder):\n",
    "        if not (f.endswith(\".jpg\") or f.endswith(\".png\")):\n",
    "            continue\n",
    "        file_path = os.path.join(aug_folder, f)\n",
    "        train_files.append(file_path)\n",
    "        train_labels.append(classes.index(cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f9f796",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creat pipelines that process images to fixed size and normalize them\n",
    "def preprocess_image(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img, img_size)\n",
    "    img = img.astype('float32') / 255.0  # Normalize to [0, 1]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cf7543",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'image_path': train_files,\n",
    "    'image_label': train_labels\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75ac26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['image_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bf2c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img_path, output_folder, aug_times):\n",
    "    img_name = os.path.basename(img_path)\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        return\n",
    "\n",
    "    img = cv2.resize(img, img_size)\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_norm = img_gray / 255.0\n",
    "\n",
    "    save_path = os.path.join(output_folder, f\"{Path(img_name).stem}_proc.png\")\n",
    "    cv2.imwrite(save_path, (img_norm*255).astype(np.uint8))\n",
    "\n",
    "    for i in range(aug_times):\n",
    "        augmented = transform(image=img_gray)\n",
    "        aug_img = augmented[\"image\"]\n",
    "        aug_save_path = os.path.join(output_folder, f\"{Path(img_name).stem}_aug{i}.png\")\n",
    "        cv2.imwrite(aug_save_path, aug_img)\n",
    "\n",
    "\n",
    "for cls in classes:\n",
    "    input_folder = os.path.join(dataset_path, cls)\n",
    "    output_folder = os.path.join(augmented_path, cls)\n",
    "    images = [os.path.join(input_folder, f) for f in os.listdir(input_folder)]\n",
    "    n_original = len(images)\n",
    "    n_target = int(np.ceil(n_original * 1.3))\n",
    "    n_aug_needed = n_target - n_original\n",
    "    aug_times = int(np.ceil(n_aug_needed / n_original))\n",
    "\n",
    "    print(f\"Processing class: {cls} ({n_original} images, {aug_times} augmentations per image)\")\n",
    "\n",
    "    Parallel(n_jobs=-1)(\n",
    "        delayed(process_image)(img_path, output_folder, aug_times) for img_path in tqdm(images)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12348e63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
